{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4eb60fc",
   "metadata": {},
   "source": [
    "1. Load the dataset provided. **(3 pts)**\n",
    "   - Ensure all columns have the correct data type, e.g., `float` or `int` for numeric quantities, `object` for categorical variables, `datetime` for dates, etc.\n",
    "   - Remove columns where all values are missing or equal to zero.\n",
    "   - Describe the basic statistics (mean, minimum, maximum, standard deviation, etc.) of the numerical variables.\n",
    "\n",
    "2. Perform all data pre-processing steps needed for the model (i.e., integration, cleaning, reduction, and transformation). **(7 pts)**  \n",
    "   For each pre-processing step that you apply, dedicate at least one markdown cell next to the code to explain:\n",
    "   - the step you are applying\n",
    "   - why you need to do it\n",
    "   - what is the result  \n",
    "\n",
    "   **Note:** In some scenarios, it is acceptable to repeat steps; however, make sure your code is logical and efficient.\n",
    "\n",
    "3. Organize your time-dependent data. In a separate markdown cell, summarize how you organize your time-dependent data. Motivate your strategy. You can include a figure if needed. **(4 pts)**\n",
    "   - **Hint:** you can include a figure in markdown syntax as follows:  \n",
    "\n",
    "4. Prepare your data for model selection and evaluation. **(4 pts)**  \n",
    "   What is the experimental setup that you use to build the model? Please provide a figure that summarizes your setup where you clearly mark:\n",
    "   - how do you split the available data for training, validation, or testing\n",
    "   - what type of validation strategy do you use (e.g., hold out, cross-validation)\n",
    "\n",
    "5. Choose a recurrent neural network architecture to build the prediction model (e.g., LSTM, GRU, etc.) and implement your solution. Motivate which hyperparameters you select or optimize. **(5 pts)**\n",
    "\n",
    "6. Create plots of training and validation losses. Describe the trends you notice and whether they indicate underfitting or overfitting behaviors. **(2 pts)**\n",
    "\n",
    "7. Evaluate the performance of the model. Describe which measures you use and discuss the results of the evaluation. **(3 pts)**\n",
    "\n",
    "8. Create a plot contrasting the predictions of the model and the ground truth values from the test set. **(2 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9990fa2b-40c9-48d3-b15b-53272cf43e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing TRAIN Dataset\n",
      "==================================================\n",
      "Dropped columns (all missing/zero): ['Biomass', 'Fossil Brown coal/Lignite', 'Fossil Coal-derived gas', 'Fossil Oil', 'Fossil Oil shale', 'Fossil Peat', 'Geothermal', 'Hydro Pumped Storage', 'Hydro Pumped Storage.1', 'Hydro Run-of-river and poundage', 'Hydro Water Reservoir', 'Marine', 'Other renewable']\n",
      "\n",
      "Numerical statistics:\n",
      "                     mean  min      max      std  missing\n",
      "Fossil Gas        3512.53  0.0   9666.0  2256.92       27\n",
      "Fossil Hard coal  1362.93  0.0   3912.0   999.45       27\n",
      "Nuclear            433.14  0.0    490.0   135.73       26\n",
      "Other              351.87  0.0  11638.0   292.84       26\n",
      "Solar               33.59  0.0    252.0    56.98       26\n",
      "Waste               62.45  0.0     89.0    17.87       27\n",
      "Wind Offshore     1296.40  0.0   3339.0   966.51       26\n",
      "Wind Onshore       431.28  0.0   1226.0   347.33       26\n",
      "\n",
      "Final columns: ['DateTime', 'Fossil Gas', 'Fossil Hard coal', 'Nuclear', 'Other', 'Solar', 'Waste', 'Wind Offshore', 'Wind Onshore']\n",
      "\n",
      "==================================================\n",
      "Processing TEST Dataset\n",
      "==================================================\n",
      "Dropped columns (all missing/zero): ['Biomass', 'Fossil Brown coal/Lignite', 'Fossil Coal-derived gas', 'Fossil Oil', 'Fossil Oil shale', 'Fossil Peat', 'Geothermal', 'Hydro Pumped Storage', 'Hydro Pumped Storage.1', 'Hydro Run-of-river and poundage', 'Hydro Water Reservoir', 'Marine', 'Other renewable']\n",
      "\n",
      "Numerical statistics:\n",
      "                     mean  min      max      std  missing\n",
      "Fossil Gas        3523.87  0.0  11004.0  2435.21       43\n",
      "Fossil Hard coal  1239.45  0.0   3926.0  1167.23       45\n",
      "Nuclear            380.55  0.0    491.0   192.32       43\n",
      "Other              173.47  0.0   2011.0   209.19       43\n",
      "Solar               32.78  0.0    251.0    54.60       44\n",
      "Waste               64.90  0.0    106.0    10.89       43\n",
      "Wind Offshore     1693.64  0.0   4384.0  1306.26       43\n",
      "Wind Onshore       376.37  0.0   1232.0   334.79       43\n",
      "\n",
      "Final columns: ['DateTime', 'Fossil Gas', 'Fossil Hard coal', 'Nuclear', 'Other', 'Solar', 'Waste', 'Wind Offshore', 'Wind Onshore']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load datasets\n",
    "train = pd.read_csv('energy_generation_train.csv')\n",
    "test = pd.read_csv('energy_generation_test.csv')\n",
    "\n",
    "def process(df, name):\n",
    "    print(f\"\\n{'='*50}\\nProcessing {name}\\n{'='*50}\")\n",
    "    \n",
    "    # Convert DateTime column (if present) to datetime\n",
    "    if 'DateTime' in df.columns:\n",
    "        df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "    \n",
    "    # Identify numeric columns (everything except DateTime)\n",
    "    numeric_cols = [c for c in df.columns if c != 'DateTime']\n",
    "    \n",
    "    # Remove columns where all values are either missing OR zero\n",
    "    # (i.e., after filling NaN with 0, all values become 0)\n",
    "    cols_to_drop = []\n",
    "    for col in numeric_cols:\n",
    "        if df[col].fillna(0).eq(0).all():\n",
    "            cols_to_drop.append(col)\n",
    "    \n",
    "    if cols_to_drop:\n",
    "        df = df.drop(columns=cols_to_drop)\n",
    "        print(f\"Dropped columns (all missing/zero): {cols_to_drop}\")\n",
    "    \n",
    "    # Remaining numeric columns\n",
    "    remaining_numeric = [c for c in df.columns if c != 'DateTime' and c in numeric_cols]\n",
    "    \n",
    "    # Basic statistics for numerical variables\n",
    "    if remaining_numeric:\n",
    "        stats = df[remaining_numeric].describe().T[['mean','min','max','std']]\n",
    "        stats['missing'] = df[remaining_numeric].isnull().sum()\n",
    "        print(\"\\nNumerical statistics:\")\n",
    "        print(stats.round(2))\n",
    "    else:\n",
    "        print(\"No numerical columns remaining.\")\n",
    "    \n",
    "    print(f\"\\nFinal columns: {list(df.columns)}\")\n",
    "    return df\n",
    "\n",
    "# Process both sets\n",
    "train_clean = process(train, 'TRAIN Dataset')\n",
    "test_clean = process(test, 'TEST Dataset')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-keras-env]",
   "language": "python",
   "name": "conda-env-tf-keras-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
